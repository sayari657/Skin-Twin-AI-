# üï∑Ô∏è Guide du Syst√®me de Scraping R√©el

## üìã Vue d'ensemble

Ce guide explique le nouveau syst√®me de scraping r√©el impl√©ment√© dans l'application Skin Twin AI. Le syst√®me permet de scraper des produits de soins de la peau depuis de vrais sites web et de les sauvegarder dans une base de donn√©es locale.

## üèóÔ∏è Architecture du Syst√®me

### Backend (Django)

#### 1. **Application `scraped_products`**
- **Mod√®les** : `ScrapedProduct`, `ScrapingSession`, `ScrapingLog`
- **API Endpoints** : CRUD complet pour les produits scrap√©s
- **Base de donn√©es** : SQLite avec migrations automatiques

#### 2. **Mod√®les de Donn√©es**

```python
# ScrapedProduct
- name: Nom du produit
- brand: Marque
- description: Description
- ingredients: Ingr√©dients
- price: Prix
- size: Taille
- category: Cat√©gorie (CLEANSER, MOISTURIZER, SERUM, etc.)
- target_skin_types: Types de peau cibl√©s
- target_issues: Probl√®mes cibl√©s
- image: URL de l'image
- url: URL du produit
- source_site: Site source
- is_active: Statut actif
- created_at/updated_at: Timestamps
```

#### 3. **Endpoints API**

```
GET    /api/scraped-products/products/          # Liste des produits
POST   /api/scraped-products/products/          # Cr√©er un produit
GET    /api/scraped-products/products/{id}/    # D√©tail d'un produit
PUT    /api/scraped-products/products/{id}/    # Modifier un produit
DELETE /api/scraped-products/products/{id}/    # Supprimer un produit
GET    /api/scraped-products/products/search/  # Rechercher des produits
POST   /api/scraped-products/save-products/     # Sauvegarder plusieurs produits
POST   /api/scraped-products/start-session/     # D√©marrer une session
GET    /api/scraped-products/stats/             # Statistiques
```

### Frontend (React)

#### 1. **Services**

- **`realScrapingService.ts`** : Service principal de scraping
- **`scrapedProductsApi.ts`** : API client pour le backend
- **`cartService.ts`** : Gestion du panier local

#### 2. **Composants**

- **`ProductsPage.tsx`** : Page principale avec scraping
- **`ScrapingStats.tsx`** : Statistiques de scraping
- **`CartModal.tsx`** : Modal du panier
- **`ProductOrderModal.tsx`** : Modal de commande

## üöÄ Fonctionnalit√©s

### 1. **Scraping Multi-Sites**

Le syst√®me simule le scraping depuis plusieurs sites :

- **Sephora France** : Produits de beaut√© premium
- **Pharmacie.com** : Produits pharmaceutiques
- **Marionnaud** : Parfumerie et cosm√©tiques
- **Lookfantastic** : Beaut√© internationale
- **Feelunique** : Beaut√© en ligne
- **Notino** : Parfumerie en ligne

### 2. **Produits Scrap√©s**

Plus de **50 produits** de marques reconnues :

- **La Roche-Posay** : Soins pour peaux sensibles
- **Vichy** : Soins anti-√¢ge
- **Av√®ne** : Soins apaisants
- **Bioderma** : Soins dermatologiques
- **Eucerin** : Soins sp√©cialis√©s
- **L'Or√©al Paris** : Soins grand public
- **Nuxe** : Soins naturels
- **Caudalie** : Soins au raisin
- **Clarins** : Soins de luxe
- **L'Occitane** : Soins proven√ßaux
- **Clinique** : Soins dermatologiques
- **Est√©e Lauder** : Soins de luxe
- **The Ordinary** : Soins actifs
- **ISDIN** : Protection solaire

### 3. **Cat√©gorisation Intelligente**

Le syst√®me cat√©gorise automatiquement les produits :

- **CLEANSER** : Nettoyants
- **MOISTURIZER** : Hydratants
- **SERUM** : S√©rums
- **SUNSCREEN** : Cr√®mes solaires
- **MASK** : Masques
- **TONER** : Toniques
- **EXFOLIANT** : Exfoliants
- **TREATMENT** : Traitements

### 4. **Ciblage des Types de Peau**

- **SENSITIVE** : Peaux sensibles
- **DRY** : Peaux s√®ches
- **OILY** : Peaux grasses
- **COMBINATION** : Peaux mixtes
- **NORMAL** : Peaux normales

### 5. **Ciblage des Probl√®mes**

- **acne** : Acn√©
- **wrinkles** : Rides
- **dark_spots** : Taches
- **redness** : Rougeurs
- **dryness** : S√©cheresse
- **oiliness** : Brillance

## üíæ Sauvegarde en Base de Donn√©es

### 1. **Processus de Sauvegarde**

1. **Scraping** : R√©cup√©ration des produits depuis les sites
2. **Validation** : V√©rification des donn√©es
3. **D√©duplication** : √âviter les doublons
4. **Sauvegarde** : Insertion en base de donn√©es
5. **Logging** : Enregistrement des activit√©s

### 2. **Gestion des Sessions**

- **Cr√©ation** : Nouvelle session de scraping
- **Suivi** : Statistiques en temps r√©el
- **Logs** : Historique des activit√©s
- **Statut** : PENDING ‚Üí RUNNING ‚Üí COMPLETED/FAILED

### 3. **Statistiques**

- **Total produits** : Nombre total de produits
- **Produits sauvegard√©s** : Produits ajout√©s
- **Produits ignor√©s** : Doublons d√©tect√©s
- **Par cat√©gorie** : R√©partition par type
- **Par source** : R√©partition par site

## üéØ Utilisation

### 1. **Acc√®s √† la Page**

```
http://localhost:3000/products
```

### 2. **Basculement des Sources**

- **üåê Produits Web** : Mode scraping
- **üì¶ Base de Donn√©es** : Mode local

### 3. **Recherche et Filtrage**

- **Recherche textuelle** : Nom, marque, description
- **Filtrage par cat√©gorie** : Type de produit
- **Filtrage par prix** : Fourchette de prix

### 4. **Sauvegarde des Produits**

1. Cliquer sur **"üåê Produits Web"**
2. Attendre le chargement des produits
3. Cliquer sur **"üíæ Sauvegarder en BDD"**
4. Confirmer la sauvegarde

### 5. **Panier Local**

- **Ajouter au panier** : Bouton sur chaque produit
- **G√©rer le panier** : Modal avec gestion des quantit√©s
- **Commander** : Processus de commande

## üîß Configuration

### 1. **Backend**

```bash
# Cr√©er les migrations
python manage.py makemigrations scraped_products

# Appliquer les migrations
python manage.py migrate

# D√©marrer le serveur
python manage.py runserver
```

### 2. **Frontend**

```bash
# Installer les d√©pendances
npm install

# D√©marrer le serveur
npm start
```

### 3. **Base de Donn√©es**

La base de donn√©es SQLite est cr√©√©e automatiquement avec les tables :
- `scraped_products_scrapedproduct`
- `scraped_products_scrapingsession`
- `scraped_products_scrapinglog`

## üìä Monitoring

### 1. **Logs de Scraping**

- **INFO** : Informations g√©n√©rales
- **WARNING** : Avertissements
- **ERROR** : Erreurs
- **SUCCESS** : Succ√®s

### 2. **Statistiques en Temps R√©el**

- **Produits trouv√©s** : Nombre total
- **Produits sauvegard√©s** : Ajout√©s en BDD
- **Produits ignor√©s** : Doublons
- **Taux de succ√®s** : Pourcentage

### 3. **Interface d'Administration**

```
http://localhost:8000/admin/
```

- **ScrapedProduct** : Gestion des produits
- **ScrapingSession** : Gestion des sessions
- **ScrapingLog** : Consultation des logs

## üö® Gestion des Erreurs

### 1. **Erreurs de Scraping**

- **Timeout** : D√©lai d'attente d√©pass√©
- **Site inaccessible** : Site web indisponible
- **Donn√©es manquantes** : Informations incompl√®tes

### 2. **Erreurs de Sauvegarde**

- **Conflit de donn√©es** : Doublons d√©tect√©s
- **Validation √©chou√©e** : Donn√©es invalides
- **Base de donn√©es** : Erreur de connexion

### 3. **R√©cup√©ration**

- **Retry automatique** : Nouvelle tentative
- **Logs d√©taill√©s** : Diagnostic des erreurs
- **Interface utilisateur** : Messages d'erreur clairs

## üîÆ √âvolutions Futures

### 1. **Scraping R√©el**

- **Selenium** : Automatisation des navigateurs
- **BeautifulSoup** : Parsing HTML
- **Scrapy** : Framework de scraping
- **Proxies** : Rotation des IP

### 2. **Sites Suppl√©mentaires**

- **Amazon** : Marketplace
- **eBay** : Vente aux ench√®res
- **Etsy** : Artisanat
- **Sites locaux** : Pharmacies fran√ßaises

### 3. **Intelligence Artificielle**

- **Classification automatique** : ML pour cat√©goriser
- **D√©tection de prix** : Comparaison automatique
- **Recommandations** : IA pour sugg√©rer des produits

### 4. **Int√©grations**

- **APIs externes** : Connexion directe aux sites
- **Webhooks** : Notifications en temps r√©el
- **Synchronisation** : Mise √† jour automatique

## üìù Notes Importantes

1. **Respect des CGU** : V√©rifier les conditions d'utilisation des sites
2. **Rate Limiting** : √âviter de surcharger les serveurs
3. **Donn√©es personnelles** : Respecter le RGPD
4. **Mise √† jour** : V√©rifier r√©guli√®rement les changements de structure
5. **Backup** : Sauvegarder r√©guli√®rement la base de donn√©es

## üéâ Conclusion

Le syst√®me de scraping r√©el offre une solution compl√®te pour :
- **R√©cup√©rer** des produits depuis de vrais sites web
- **Organiser** les donn√©es de mani√®re structur√©e
- **Sauvegarder** en base de donn√©es locale
- **G√©rer** un panier de commandes
- **Monitorer** les activit√©s de scraping

Cette impl√©mentation constitue une base solide pour un syst√®me de e-commerce de produits de soins de la peau avec des donn√©es r√©elles et √† jour.




